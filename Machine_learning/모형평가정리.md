## **1. 오버피팅과 언더피팅**

### 1.1. 오버피팅
**특정 데이터 셋에 과도하게 적합된 것을 의미**
- 정확도가 높아 보이지만, 알려지지 않은 데이터에 대한 예측력은 낮음
- 새로운 데이터 셋에 적용하만 큰 오차를 보임
### 1.2. 언더피팅
**데이터 셋에 적합이 잘 되지 않은, 과소 적합된 상황**
- 데이터의 특성을 잘 나태내지 못함
### 1.3. 수식을 통해 확인
실제 모형이 n 차원 식일 때, 추정한 모형이 n 보다 큰 차원의 식으로 표현된다면 ==오버피팅,== n 보다 작은 차원의 식으로 적합되었다면 ==언더피팅==되었다고 함 

**편향-분산 트레이드오프란?**
편향이 낮을 수록 분산은 커지고, 편향이 높을수록 분산이 작아지는 경향
-> 모형 복잡 : 오버피팅 가능성 높음(분산이 커진다)
-> 모형 간단 : 언더피팅 가능성 높음(편향이 커진다)

---
## **2. 크로스-밸리데이션**

**파라미터란?** 
모형 내부에서 데이터에 의해 추정되는 값

**하이퍼파라미터란?**
모형 생성에 쓰이는 데이터로부터 나온 값이 아니고, 사용자가 직접 정하는 값
-> **기존의 문제 : 트레이닝 데이터와 테스트 데이터만 존재한다면, 모형의 하이퍼파라미터가 테스트 데이터에 의존함**

>**해결법**
>**벨리데이션 데이터 사용**

#### 크로스-밸리데이션(K-fold cross-validation)**
전체 데이터를 k개로 분할한 후 트레이닝, 밸리데이션 데이터 조합을 바꾸는 방법

---
## **3. 파이프라인**
-> 데이터 전처리와 학습 모형을 연결해 코드를 간결화

#### 파이프라인 적용하기 전 학습 과정
```python
# 표준화 스케일링
std_scale = StandardScaler()
X_tn_std = std_scale.fit_transform(X_tn)
X_te_std = std_scale.transform(X_te)

# 학습
clf_linear = LinearRegression()
clf_linear.fit(X_tn_std, y_tn)
```

#### 파이프라인 사용한 코드
```python
from sklearn.pipeline import Pipeline
# 파이프라인
linear_pipline = Pipeline([
	('scaler', StandardScaler()),
	('linear_regression', LinearRegression())
])

# 학습
linear_pipline.fit(X_tn, y_tn)
```

---
## **4. 그리드 서치**
관심 있는 매개 변수들을 대상으로 학습 가능하도록 만드는 방식
(어떤 하이퍼파라미터 k가 가장 높은 성능을 보일지는 직접 학습하기 전에는 알 수 없음)

```python
best_accuracy = 0
for k in [1,2,3,4,5,6,7,8,9,10]:
	clf_knn = KNeighborsClassifier(n_neighbors=k)
	clf_knn.fit(X_tn_std, y_tn)
	knn_pred = clf_knn.predict(X_te_std)
	accuracy = accuracy_score(y_te, knn_pred)
	if accuracy > best_accuracy:
		best_accuracy = accuracy
		final_k = {'k': k}
```

---
## **5. 손실 함수와 비용 함수**

### **5.1 손실 함수** 
머신러닝을 통해 생성한 모형이 실젯값과 얼마나 차이가 나는지 
**즉, 손실 정도를 수치로 나타내는 함수**
- 각 데이터 포인트에 대해 예측값과 실젯값의 차이를 나타냄

### **5.2 비용 함수**
- 데이터 셋 전체를 대상으로 하는 손실을 의미

### **5.3 L1 손실 함수**

$$
L1 \, Loss = \sum|y_{true} - y_{predict}|
$$
-  $y_{true}$는 실젯값을 의미 $y_{predict}$는 학습 모형을 이용해 예측한 값
- 실젯값과 예측값의 차이에 기댓값을 취한 것
- **즉, 차이를 줄이는 것이 학습 목적** 


> [!NOTE] L1 손실과 관련된 비용 함수 : MAE(Mean Absolute Error)
> $MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i-\hat{y_i}|$
> L1 Loss의 평균을 나타내는 비용 함수

### **5.4. L2 손실함수**
실젯값과 예측값의 차이에 제곱을 취함
$$
L2 \, Loss = \sum(y_{true} - y_{predict})^2
$$
$$
MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y_i})^2
$$
$$
RMSE = \sqrt{MSE}
$$

#### MSE?
실젯값과 예측값의 차이의 제곱의 평균 
-> **실젯값과 예측값을 제곱하므로 이상치의 변화에 민감함**

**따라서, 이상치에 중점을 두고 싶다면 MSE를 사용, 그렇치 않다면 MAE나 RMSE를 사용**

### **5.5 엔트로피**
정보 이론에서 사용하는 개념으로 확률 변수의 불확실성 정도를 측정

#### 엔트로피
$$
Entropy(P)= -\sum P(x)logP(x) = -E(logP(x))
$$

#### 크로스 엔트로피
$$
CrossEntropy(P, Q)= -\sum P(x)logQ(x) = -E_p(logQ(x))
$$
- P(x) : 실제 모형의 분포
- Q(x) : 추정 모형의 분포

#### Kullback-Leibler Divergence(KLD, 상대적 엔트로피)
$$
D_{KL}(P || Q) = \sum P(x)log\frac{P(x)}{Q(x)} \\ = -\sum P(x)logQ(x) + \sum P(x)logP(x) \\ = - E_p(log\frac{P(x)}{Q(x)})
$$

#### Negative Log Likelihood(NLL)
$$
Negative\:log\: likelihood = -logf(x_i|\theta)
$$

**로그 가능도 함수를 최대화하려는 파라미터를 찾는 문제는 크로스-엔트로피를 최소화하는 파라미터를 찾는 문제와 동일하므로 NLL을 손실함수로 사용할 수 있음**

---

## **6. 모형 성능평가**

#### **6.1. 혼동행렬(confusion matrix)**
<table > 
<tr> 
	<th rowspan="2" colspan="2"></th> 
	<th colspan="2">예측</th> 
</tr> 
<tr> 
	<td>양성</td> 
	<td>음성</td> 
</tr>
<tr>
	<td rowspan="2">실제</td>
	<td>양성</td>
	<td>True Positive(TP)</td>
	<td>False Negative(FN)</td>
</tr>
<tr>
	<td>음성</td>
	<td>False Positive(FP)</td>
	<td>True Negative(TN)</td>
</tr>
</table>

#### **6.2. 정밀도(Precision)**
양성으로 예측했을 때, 실제로 양성으로 나타나는 비율
$$
precision = \frac{TP}{TP+FP}
$$

#### **6.3. 리콜(Recall), 민감도(Sensitivity)**
양성에 해당하는 사람이 양성으로 예측되는 비율
$$
recall = \frac{TP}{TP+FN}
$$
#### **6.4. 특이도(Specificity)**
음성에 해당하는 사람이 음성으로 예측되는 경우
$$
specificity = \frac{TN}{FP+TN}
$$
#### **6.5. False Positive Rate(FRR)**
실제로 음성에 해당하는 사람이 양성으로 예측되는 경우의 비율
$$
FPR = 1-specificity = \frac{FP}{FP+TN}
$$
#### **6.6. 정확도(Accuracy)**
전체 데이터 중 정답으로 분류되는 비율
$$
정확도 = \frac{TP+TN}{TP+FP+FN+TN}
$$
#### **6.7. 에러율(Error Rate)**
전체 데이터 중 오답으로 분류되는 비율
$$
정확도 = \frac{FP+FN}{TP+FP+FN+TN}
$$
#### **6.8. ROC 커브(Receiver Operating Characteristic)**
'수신자 조작 특성', X축에 FPR(False Positive RAte)을 놓고 Y축에는 민감도(Sensitivity)의 값을 비교
-> **곡선 아래의 면적이 높을수록 높은 성능을 의미**

### **분류 문제에서의 성능 평가**

#### **6.9. 정확도(accuracy)**
$$
accuracy = \frac{1}{n}\sum_{i=1}^{n}I(\hat{y_i} = y_i)
$$
I는 지시함수로 $\hat{y_i} 와 y_i$ 의 값이 동일하다면 1, 서로 다르면 0을 가진다는 것을 의미

```python
>>> from sklearn.metrics import accuracy_score
>>> y_pred = [0, 2, 1, 3]
>>> y_true = [0, 1, 2, 3]
>>> print(accuracy_score(y_true, y_pred))
0.5
>>> print(accuracy_score(y_true, y_pred, normalize=False))
2
```
* normalize=False 옵션을 사용하면 **빈도수**가 출력

#### **6.9. F1 score**
**precision과 recall의 조화 평균값 , 1에 가까울수록 높은 성능을 나타냄**
$$
F1\;Score = 2 \times \frac{precision \times recall}{precision + recall}
$$
##### **Confusion Matrix**
```python
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
	   [0, 0, 1],
	   [1, 0, 2],
])
```
* 행은 실젯값을 의미, 열은 예측값을 의미
* 대각 원소는 예측값과 실젯값이 일치하는 경우

##### **classification report**
```python
>>> from sklearn.metrics import classification_report
>>> y_true = [0, 1, 2, 2, 0]
>>> y_pred = [0, 0, 2, 1, 0]
>>> target_names = ['class 0', 'class 1', 'class 2']
>>> print(classification_report(y_true, y_pred, target_names=target_names))
```

### **회귀 문제에서의 성능 평가**

##### **Mean Absolute Error(MAE)**
$$
MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i-\hat{y_i}|
$$
```python
>>> from sklearn.metrics import mean_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> print(mean_absolute_error(y_true, y_pred))
0.5
```

##### **Mean Squared Error(MSE)**
오차 제곱합합
$$
MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y_i})^2
$$
```python
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> print(mean_squared_error(y_true, y_pred))
0.375
```

##### **r2 score**
R 제곱값, 전체 모형에서 설명 가능한 분산의 비율을 나타냄. 
R 제곱값은 0에서 1 사잇값을 가지며 **1에 가까울수록 높은 성능**을 의미
$$
R^2=1-\frac{\sum^n_1(y_i - \hat{y_i})}{\sum^n_1(y_i - \bar{y_i})}
$$
```python
>>> from sklearn.metrics import r2_score
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> print(r2_score(y_true, y_pred))
0.9486
```

### **군집 문제에서의 성능 평가**
##### **실루엣 스코어**
서로 다른 군집이 얼마나 잘 분리되는지를 나타내는 지표
>같은 군집의 데이터는 가까운 거리에 뭉쳐있고, 다른 군집의 데이터끼리는 멀리 떨어져 있을 수록 높은 점수를 나타냄 

- a : 집단 내 데이터 거리 평균
- b : 다른 집단 데이터 거리 평균의 최솟값

**-1 부터 1 사이의 값을 가지며 스코어 높을수록 좋은 성능을 의미**
$$
s = \frac{b-a}{max(a, b)}
$$
```python
>>> from sklearn.metrics import silhouette_score
>>> X = [[1, 2], [4, 5], [2, 1], [6, 7], [2, 3]]
>>> labels = [0, 1, 0, 1, 0]
>>> sil_score = silhouette_score(X, labels)
>>> print(sil_score)
0.5789497702625118
```



